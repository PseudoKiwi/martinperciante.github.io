<!DOCTYPE HTML>
<!--
	Directive by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Directive by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Main -->
			<div id="main">

				<div class="box container">
					<header> 
						<h2>Optimization</h2>
					</header>

					<section>
						<header>
							<h3 style="text-align: left">Introduction</h3>
						</header>
						<p style="text-align: justify">
							To optimize implies to maximize or minimize some kind of outup, depending on the problem we are facing. In programming, it is usual to use
							algorithms that minimize the execution time. A more efficient algorithm will do the same job in less time. In Machine Learning context, we
							want to minimize what we call the cost function. In Linear Regression, the cost function is just the cuadratic error of the model.
						</p>
						<header>
							<h3 style="text-align: left">Gradient Descent</h3>
						</header>
						<p style="text-align: justify">
							The Gradient Descent algorithm makes use of some mathematical properties of functions to minimize them. The gradient operator applied to a
							scalar function gives us information about its direction of greatest growth. Given a starting point, we can periodicly move in the coordinate
							space contrary to that direction until, with some tolerance, we find a minimum value.
						</p>
						<p style="text-align: justify">
							Some problems arise from this approach. It can happen that the minimum we found its far from what we are looking for. Relative minimums are
							also minimums and we need a way to avoid them. Consequently, the use of a new parameter is proposed. This parameter regulates the step length and
							must be a real, positive value. With a large enough step parameter, relative minimums are easier to dodge, but a convergence problem arises. Big
							steps prevents the algorithm to found a suitable set of candidate coordinates, failing its porpouse. Another problem are saddle points, where the
							function has null gradient but its not a minimum nor maximum. Having the step parameter well defined, the only thing to worry about now is the starting
							point. Choosing a random sart will make it difficult to converge in a saddle point.
						</p>
						<p style="text-align: justify">
							In conclusion, the starting point and value of the step parameter are crucial for the correct functioning of our algorithm, but how can we apply it?
							To calculate the next values of the coordinates we need a starting point (as mentioned before), the value of the step parameter and the gradient
							of the function. Having this, the new values will be computed as the actual values minus the step parameter times the gradient evaluated in the actual
							coordinates. The problem with this implementation cames with big datasets, because we first compute all the next values and then apply the transformation.
						</p>
						<header>
							<h3 style="text-align: left">Other variants</h3>
						</header>
						<p style="text-align: justify">
							Different implementations of this method were developed through the years. Before I discussed about an implementation with a fixed value for the
							step parameter. Some algorithms use a dinamic step parameter, calculating its value for each iteration, so convergence is achieved faster and better.
						</p>
						<p style="text-align: justify">
							Another change is the Stochastic Gradient Descent. In this case, the transformation of coordinates is not applied to all at once, but to one random
							one at a time. This is an advantage to the first case when treating big datasets.	
						</p>

						<!-- Phasellus nisl nisl, varius id <sup>porttitor sed pellentesque</sup> ac orci. Pellentesque
						habitant <strong>strong</strong> tristique <b>bold</b> et netus <i>italic</i> malesuada <em>emphasized</em> ac turpis egestas. Morbi
						leo suscipit ut. Praesent <sub>id turpis vitae</sub> turpis pretium ultricies. Vestibulum sit
						amet risus elit.
						</p>
						-->
					</section>
					<ul class="icons">
						<li><a href="index.html" class="fas fa-arrow-left"></a></li>
					</ul>
					<!--
					<p>Tellus erat mauris ipsum fermentum<br />
					etiam vivamus nunc nibh morbi.</p>
					-->
				</div>
			</div>
				
		<!-- Footer -->
		<div id="footer">
			<div class="container medium">
				<section>
					<header>
						<h2>Contact info</h2>
					</header>
					<hr />
					<section>
						<h4>Address</h4>
						<p>Dr. Joaqu√≠n Secco Illa 2827</p>
					</section>
					<hr />
					<section>
						<h4>Phone</h4>
						<p>(+598) 95 451 306</p>
					</section>
					<hr />
					<section>
						<h4>Email</h4>
						<p>tincho.perciante@gmail.com</p>
					</section>
				</section>
				<hr />
				
				<ul class="copyright">
					<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
